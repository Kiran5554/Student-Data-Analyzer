{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cognitive Skills & Student Performance Analysis\n",
        "\n",
        "## Introduction & Objective\n",
        "\n",
        "This notebook explores the relationship between cognitive skills and student assessment performance using a synthetic dataset. We perform EDA, correlation analysis, regression modeling, clustering, and generate actionable insights for instructors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# Ensure output directory exists\n",
        "os.makedirs('notebooks/outputs', exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load & Describe Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('../data/students.csv')\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploratory Data Analysis (EDA)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Histograms\n",
        "features = ['comprehension', 'attention', 'focus', 'retention', 'engagement_time', 'assessment_score']\n",
        "df[features].hist(bins=20, figsize=(12,8))\n",
        "plt.tight_layout()\n",
        "plt.savefig('notebooks/outputs/histograms.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pairwise scatter plots\n",
        "sns.pairplot(df[features])\n",
        "plt.savefig('notebooks/outputs/pairplot.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation matrix\n",
        "corr = df[features].corr()\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.savefig('notebooks/outputs/corr_matrix.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Interpretation:**\n",
        "\n",
        "Assessment score is expected to be most strongly correlated with comprehension, attention, focus, retention, and engagement time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standardize features\n",
        "X = df[['comprehension', 'attention', 'focus', 'retention', 'engagement_time']]\n",
        "y = df['assessment_score']\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "# Optionally add interaction features here\n",
        "# ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modeling: Regression to Predict Assessment Score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Baseline: Linear Regression\n",
        "lr = LinearRegression()\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "mae = -cross_val_score(lr, X_scaled, y, cv=cv, scoring='neg_mean_absolute_error').mean()\n",
        "rmse = np.sqrt(-cross_val_score(lr, X_scaled, y, cv=cv, scoring='neg_mean_squared_error').mean())\n",
        "r2 = cross_val_score(lr, X_scaled, y, cv=cv, scoring='r2').mean()\n",
        "print(f'Linear Regression MAE: {mae:.2f}, RMSE: {rmse:.2f}, R²: {r2:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stronger: Random Forest with GridSearchCV\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "param_grid = {'n_estimators': [50, 100], 'max_depth': [None, 5, 10]}\n",
        "grid = GridSearchCV(rf, param_grid, cv=cv, scoring='neg_mean_absolute_error')\n",
        "grid.fit(X_scaled, y)\n",
        "best_rf = grid.best_estimator_\n",
        "y_pred = best_rf.predict(X_scaled)\n",
        "mae_rf = mean_absolute_error(y, y_pred)\n",
        "rmse_rf = np.sqrt(mean_squared_error(y, y_pred))\n",
        "r2_rf = r2_score(y, y_pred)\n",
        "print(f'Random Forest MAE: {mae_rf:.2f}, RMSE: {rmse_rf:.2f}, R²: {r2_rf:.2f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Model & Preprocessing Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "pipeline = make_pipeline(StandardScaler(), best_rf)\n",
        "os.makedirs('../models', exist_ok=True)\n",
        "joblib.dump(pipeline, '../models/pipeline.pkl')\n",
        "print('Pipeline saved to ../models/pipeline.pkl')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clustering: Learning Personas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize cognitive features\n",
        "cog_features = ['comprehension', 'attention', 'focus', 'retention', 'engagement_time']\n",
        "X_cog = scaler.fit_transform(df[cog_features])\n",
        "# Elbow method\n",
        "inertia = []\n",
        "silhouette = []\n",
        "for k in range(2, 7):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(X_cog)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "    silhouette.append(silhouette_score(X_cog, kmeans.labels_))\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(range(2,7), inertia, marker='o')\n",
        "plt.title('Elbow Method')\n",
        "plt.xlabel('n_clusters')\n",
        "plt.ylabel('Inertia')\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(range(2,7), silhouette, marker='o', color='orange')\n",
        "plt.title('Silhouette Score')\n",
        "plt.xlabel('n_clusters')\n",
        "plt.ylabel('Silhouette')\n",
        "plt.tight_layout()\n",
        "plt.savefig('notebooks/outputs/clustering_metrics.png')\n",
        "plt.show()\n",
        "# Choose best k (e.g., 4)\n",
        "best_k = 4\n",
        "kmeans = KMeans(n_clusters=best_k, random_state=42)\n",
        "clusters = kmeans.fit_predict(X_cog)\n",
        "df['cluster'] = clusters\n",
        "# Save with clusters\n",
        "df.to_csv('../data/students_with_clusters.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Persona Descriptions\n",
        "\n",
        "For each cluster, we describe the persona and suggest teaching strategies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "persona_desc = []\n",
        "for c in range(best_k):\n",
        "    group = df[df['cluster'] == c]\n",
        "    avg = group[cog_features].mean()\n",
        "    desc = f'Cluster {c}: ' \\\n",
        "        f'Comprehension={avg[\"comprehension\"]:.1f}, Attention={avg[\"attention\"]:.1f}, Focus={avg[\"focus\"]:.1f}, Retention={avg[\"retention\"]:.1f}, Engagement={avg[\"engagement_time\"]:.1f}'\n",
        "    # Simple rule-based persona\n",
        "    if avg['attention'] < 60 and avg['retention'] < 60:\n",
        "        persona = 'Needs revision-based learning'\n",
        "        recs = 'Use spaced repetition, regular quizzes.'\n",
        "    elif avg['comprehension'] > 75 and avg['focus'] > 75:\n",
        "        persona = 'Self-motivated high performer'\n",
        "        recs = 'Offer advanced material, encourage peer teaching.'\n",
        "    elif avg['engagement_time'] < 120:\n",
        "        persona = 'Low engagement risk'\n",
        "        recs = 'Increase interactive activities, parental involvement.'\n",
        "    else:\n",
        "        persona = 'Average learner'\n",
        "        recs = 'Monitor progress, provide balanced support.'\n",
        "    persona_desc.append((desc, persona, recs))\n",
        "for desc, persona, recs in persona_desc:\n",
        "    print(f'{desc} -> {persona}. Recommendations: {recs}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Insights & Recommendations\n",
        "\n",
        "1. Assessment scores are most strongly correlated with comprehension and focus.\n",
        "2. Students with low engagement time tend to underperform.\n",
        "3. Cluster analysis reveals distinct learning personas.\n",
        "4. Random Forest outperforms linear regression in predictive accuracy.\n",
        "5. Instructors should tailor strategies based on cluster personas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export Artifacts\n",
        "\n",
        "All figures are saved to `notebooks/outputs/`. Model pipeline is saved to `../models/pipeline.pkl`. Clustered data is saved to `../data/students_with_clusters.csv`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample code to load pipeline and predict for new students\n",
        "def predict_sample(new_data):\n",
        "    pipeline = joblib.load('../models/pipeline.pkl')\n",
        "    return pipeline.predict(new_data)\n",
        "\n",
        "# Example usage:\n",
        "# new_students = pd.DataFrame({\n",
        "#     'comprehension': [80],\n",
        "#     'attention': [75],\n",
        "#     'focus': [78],\n",
        "#     'retention': [70],\n",
        "#     'engagement_time': [200]\n",
        "# })\n",
        "# print(predict_sample(new_students))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
